     https://madewithml.com/

          https://github/alexeygrigorev/mlbookcamp-code
          https://github/GokuMohandas/Made with ML.
          MIT 6.S191: Introduction to deep learning
          https://github.com/IbrahimSobh/Practical-DRL
          https://IbrahimSobh.github.io/Practical-DRL/
          Standford CS25-Transformers united
          CS25|standford Seminar-Decision Transformer: Reinforcement Learning via Sequence Modeling
          Standford CS224: Machine Learning with Graphs.
          https://theaisummer.com/diffusion-models/
          https://huggingface/diffusers.
          https://guytevet.github.io/mdm-page/: Human Motion diffusion Model.
    
          https://github/GokuMohandas/MLOPs-course
          https://github.com/DataTalksClub/mlops-zoomcamp
          https://github.com/DataTalksClub/data-engineering-zoomcamp
          https://https://lilianweng.github.io/posts/

         https://huggingface.co




0-Data generation with Latent variable models:

    - RGB to infrared data, diffuseurs

             *InfraGAN: A GAN architecture to transfer visible images to infrared domain 2022(Pix2Pix, CycleGAN, thermaGAN)
             *https://towardsdatascience.com/what-are-stable-diffusion-models-and-why-are-they-a-step-forward-for-image-generation-aa1182801d46.
             *https://lilianweng.github.io/posts/2021-07-11-diffusion-models/
             *https://theaisummer.com/diffusion-models/
             *Inside Meta AI’s Make-A-Video: The New Super Model that can Generate Videos from Textual Input.
             *Generative adversarial networks for visible to infrared video conversion 2020.
            *Synthetic data generation for end-to-end thermal infrared tracking 2018.
            *Transgan: Two transformers can make one strong gan 2021.
        LLVIP dataset can contribute to the community of computer vision by promoting image fusion, pedestrian detection and image-to-image translation 
        in very low-light applications （The wavelength: 8~14um (thermal infrared images)):pix2pixGAN, imagefusion_densefuse, FusionGAN

   - data transformation, regularization and augmentation strategies timm
   - Torchvision s' transforms API now support native object detection, segmentation &videos tasks
         pytorch.org/blog/Extending Torchvision's Transforms to object detetcion, segmentation & videos tasks
   - how to perform Data augmentation in NLP projects: https://bit.ly/3FGjQvD
   -

1-Supervised Learning for dense Vision tasks in infrared videos


      
    
     https://github.com/DirtyHarryLYL/Transformer-in-Vision
     Attention mechanisms and deep learning for machine vision: A survey of the state of the art 2021.
     BERT Baseline - Kaggle




1-1-object Detection for outdoor surveillance and intrusion detetcion
         *End-to-end  object detection with transformers 2020.
         *Training data-efficient image transformers & distillation through attention 2021.
1-2-object Segmentation for outdoor surveillance and intrusion detetcion:
        *
        *Training data-efficient image transformers & distillation through attention 2021.
1-3 object Classification for outdoor surveillance and intrusion detetcion:

                   *An image is worth 16x16 words: transformers for image recognition at scale 2021.
                   *Training data-efficient image transformers & distillation through attention 2021.

1-4 object Localization  for outdoor surveillance and intrusion detetcion:
                   *Training data-efficient image transformers & distillation through attention 2021.
1-5-Tracking:
        *Deep learning for visual tracking: A comprehensive survey 2021.
        *Efficient Visual  Tracking  with exemplar transformers 2022.
        *SwinTrack: A Simple and Strong Baseline for Transformer Tracking 2021.
        *Tracking: LiDAR-based 3D Object Tracking with Transformer framework .
                     *Reference: 3D Object Tracking with Transformer 2021.(LTTR)
                                           Transformers in 3D Point Clouds: A Survey, 2022.

        *End-to-end human pose and mesh reconstruction with transformers 2021.
            
1-6-Outlier/anomaly detetcion:

1-7 - Unified /generalizable Framework for Real-world Skeleton Action Recognition
         Action recognition based on skeleton data has recently witnessed increasing attention and progress.
         State-of-theart approaches can effectively extract features on human skeletons relying on the pre-defined human topology.
      
       Reference:
              *https://github.com/negarhdr/skeleton-based-action-recognition/
              *https://github.com/YangDi666/UNIK
              * VISION TRANSFORMERS FOR ACTION RECOGNITION: A SURVEY 2022.
              *Spatial temporal transformer network for skeleton-based action recognition 2021.


1-8- Multi-modal Action Recognition:

                          - RGB videos.
                         - depth map sequences.
                         - 3D skeletal data (3D coordinates of 25 major body joints)
                         - infrared (IR) videos.
        *Knowledge Distillation for Action Recognition Based on RGB and Infrared Videos 2022.
        * VISION TRANSFORMERS FOR ACTION RECOGNITION: A SURVEY 2022.
         *Video Transformers: A Survey, 2022
         *Video Action Transformer Network 2019.
         *Vivit: A video vision transformer 2021.

        *Actort-ransformers for group activity recognition. 2020.


        *Ttpp: Temporal transformer with progressive prediction for efficient action anticipation 2021.
        *Bridging the gap between Human Action Recognition and Online Action Detection 2021.



1-9-Egocentric Vision-based situation Recognition:

          -Egocentric Vision-based Action Recognition: A survey   2022.
         - Trear: Transformer-based rgb-d egocentric action recognition 2021.
          https://github.com/EgocentricVision
          https://github.com/EgocentricVision#datasets, EPIC kitchen, etc: see for pfe, #repositories.
         
         multi-view camera (vision)

1-10-Visual language Learning for grounded situation description (Vision and Language)
     UniT: Multimodal Multitask Learning with a Unified Transformer
     Multimodal Incremental Transformer with Visual Grounding for Visual Dialogue Generation 2021.
     Reference:
              *https://mmf.sh/docs
              * https://github.com/facebookresearch/mmf
              * Vision-language Pre-training: Basics, recent Advances, and Future Trends 2021.

1-11- Named entity recognition for grounded situation recognition:  
    

     Reference:
       * Vision-language Pre-training: Basics, recent Advances, and Future Trends 2021.
      * https://github.com/allenai/swig,
      * https://github.com/TheShadow29/vognet-pytorch, 
       *https://github.com/jhcho99/gsrtr, https://github.com/jhcho99/
       * Vision-and-Language Pretrained Models: A Survey, 2022.

      - Named-entity recognition platforms
          Notable NER platforms include:

               *GATE supports NER across many languages and domains out of the box, usable via a graphical interface and a Java API.
               *OpenNLP includes rule-based and statistical named-entity recognition.
               *SpaCy features fast statistical NER as well as an open-source named-entity visualizer.

     - Named entity recognition models in huggingface.
     - SayCan: Do  As I can, Not as Isay: Grounding Language in Robotivs Affordances 2022(see blog, google-AI-youtube, Demo, github)

Pretrained models similar to our specific task,  fine tuning with different fine-tuning schemes: see DINO may be.
This process will also achieve better results than training from scratch (unless you have lots of data),
which is why you should always try to leverage a pretrained model — one as close as possible to the task you have at hand — and fine-tune it.


pfe: https:// meduim.com/standford-cs224w/graphs-are-all-you-need-generating-multi-modal-representations-for-vqa-744a8a1ad448:
multi-modal graph Networks for compositonal generalization in visual questionning answering (Princeton university, NIPS 2020)

idea: predicts the trajectory of the eye from the input image.(AI-Scolar)




1-12- facial expression recognition  # see Thales also: thermal face and landmark detection for unconstrained cross-spectral face recognition UCB2022.
      Charlotte-ThermalFace: A Fully Annotated Thermal Infrared Face Dataset with Various Environmental Conditions and Distances 2022.
      - Using Facial Landmark Detection on Thermal Images as a Novel Prognostic Tool for Emergency Departments 2022.
      - Face Recognition in Unconstrained Conditions: A Systematic Review 2019
      - Multispectral Facial Recognition in the Wild 2022
      - Heterogeneous Visible-Thermal and Visible-Infrared Face Recognition Using Cross-Modality Discriminator Network and Unit-Class Loss



      unconstrained face recognition:Labeled Faces in the Wild datset(LFW Face Database)
1-13-Hand Gesture Languages:
                   https://aiia.csd.auth.gr/auth-uav-gesture-dataset/  ( infrared, skeleton)
                   Multi-Modal Dataset for Hand Gesture Recognition:
                        https://www.kaggle.com/datasets/gti-upm/multimodhandgestrec

1-14-Hyper_parameter optimization with Nature Inspired metaheuristic optimization algorithms

2-Self supervised Learning on images , videos, depth maps, skeletons for  outdoor surveillance and intrusion detetcion.

     Recently, computer vision systems have made considerable progress. Most of them are still based on supervised learning. 
     However, the success of such a learning paradigm relies on a large amount of labeled data, which is not always available, 
     is often prohibitively expensive to acquire, and is hampered by the cost of the required human annotation.
     Furthermore, these supervised systems are tailored to specific scenarios, for example a model trained on the ImageNet dataset (ILSVRC-2012) 
     can only recognize 1000 semantic categories or a model trained to perceive road traffic in daylight may not work in the dark. 
     It is simply not possible to collect labeled data for all the things we would like machines to do and we cannot label more and more data. 


     Therefore, a major research effort is currently devoted to systems that can adapt to new conditions without the need for expensive supervision. 
     This effort includes recent advances in transfer learning, domain adaptation, semi-supervised, weakly supervised, unsupervised 
     and self-supervised learning.

       Self-supervised transformers can produce finer features than those obtained by supervised approaches without any labeling load.  

            *M3Video: Masked Motion Modeling for Self-Supervised Video Representation Learning 2022.
            *Video Transformers: A Survey, 2022
            *https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html:
            *Transformers in Action: Weakly Supervised Action Segmentation 2022.
            *Google’s SimCLR library: https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html
            *Self supervised Library: jrodthoughts.meduim.com/Lightly is one of the first open source frameworks for self supervised learning
                 - https://github.com/lightly-ai/lightly
          
                  Barlow Twins
                  BYOL
                  DCL & DCLW
                  DINO
                  MAE
                  MSN
                  MoCo
                  NNCLR
                  SimCLR
                  SimSiam
                  SMoG
                  SwaV
     for Sketon data: Self-supervised 3D Skeleton Action Representation Learning with Motion Consistency and Continuity 2021.
                      Self-supervised 3D hand pose estimation through training by fitting 221. (hand tracking)



3-General purpose backbone learning for dense vision tasks:
    
      * Large-batch Optimization for Dense Visual Predictions 2022_https://github.com/Sense-X/AGVM
      *Vision transformers for dense prediction, 2021


   
4-General purpose model (All for One:  Multi-Task)

                   https://cs224d.stanford.edu/reports/McCannRoth.pdf

                   Gato:https://github.com/OrigamiDream/Gato
   
 5-Fusion : 
 6-Interpretable model:
     complex event processing, Dynamic IR challenges
       VEKG: Video Event Knowledge Graph to Represent Video Streams for Complex Event Pattern Matching 2019
 7-Neuroscience module:
     bog of facebook/Martin Ciupa: consciousnesss is an important topic.  
             Transdisciplinity and consciousness; toward an integrated  model 
             quantim mechanisms
 8-Federated  Learning:
                        -FLED-Block: Federated Learning Ensembled Deep Learning Blockchain Model for COVID-19 Prediction, 2022.
                        -International Joint Conference on Neural Networks 2022 (IJCNN) on  Federated Learning  and Cooperative Neural Network (CoNN): 18-23 July 2022.
                        -Applications and Challenges of Federated Learning Paradigm in the Big Data Era with Special Emphasis on COVID-19 2022.
                        -federated self supervised learning for acoustic event classification 2022.
9-Meta Learning:
               Environment Adaptive RFID-Based 3D Human Pose Tracking With a Meta-Learning Approach 2022.

10-Deploy the application into production.

Surveillance system

MTEB: Massive Text Embedding Benchmark: https://huggingface.co/blog/mteb
     MTEB is a massive benchmark for measuring the performance of text embedding models on diverse embedding tasks.
     https://huggingface.co/spaces/mteb/leaderboard


11- Mixed reality/3D representation

 

12-SLAM and Deep Learning for 3D Indoor Scene Understanding 2018.(John B. McCormac)

13- Visualization/Computer graphics

       Tableau



Try to use your custdom dataset: see blogs can help you/ colab 
Extend Classifying each word in a sentence tasks to videos

pfe: https://huggingface.co/blog/train-decision-transformers




Next step :  try to put ViT, Detr into  commun plateform,  pipeline


%https://github.com/fc7/LaTeX-Decode
#https://metacpan.org/dist/LaTeX-Decode/view/bin/latex2utf8










