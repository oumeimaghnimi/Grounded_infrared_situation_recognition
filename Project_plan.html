     https://madewithml.com/
          https://www.kaggle.com/learn/
          https://fullstackdeeplearning.com/spring2021/
          https://github/alexeygrigorev/mlbookcamp-code
          https://github/GokuMohandas/Made with ML.
          MIT 6.S191: Introduction to deep learning
          https://github.com/IbrahimSobh/Practical-DRL
          https://IbrahimSobh.github.io/Practical-DRL/
          Standford CS25-Transformers united
          CS25|standford Seminar-Decision Transformer: Reinforcement Learning via Sequence Modeling
          Standford CS224: Machine Learning with Graphs.
          https://theaisummer.com/diffusion-models/
          https://huggingface/diffusers.
          https://guytevet.github.io/mdm-page/: Human Motion diffusion Model.
    
          https://github/GokuMohandas/MLOPs-course
          https://github.com/DataTalksClub/mlops-zoomcamp
          https://github.com/DataTalksClub/data-engineering-zoomcamp
          https://https://lilianweng.github.io/posts/

         https://huggingface.co

Co-training Transformer with Videos and Images Improves Action Recognition 2021.
https://ai.googleblog.com/2022/03/co-training-transformer-with-videos-and.html:
         Bowen Zhang, Student Researcher and Jiahui Yu, Senior Research Scientist, Google Research, Brain Team.
      *CoVeR adopts a multi-task learning strategy trained on multiple datasets, each with their own classifier.
         TimeSFormer, Video SwinTransformer, TokenLearner, ViViT, MoViNet, VATT, VidTr, and OmniSource 


*https://bleedai.com/building-a-smart-intruder-detection-system-with-opencv-and-your-phone/
*system surveillance building
*Infared definition
**Multi modal movie dataset (scenes in the wild): https://github.com/huggingface/transformers/tree/main/examples/research_projects/mm-imdb

*https://huggingface.co/docs/transformers/main_classes/trainer
    
    https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification
    https://github.com/huggingface/transformers/tree/main/examples/pytorch
    https://github.com/huggingface/transformers/tree/main/examples/research_projects


0-Data generation with Latent variable models:

    - RGB to infrared data, diffuseurs

             *InfraGAN: A GAN architecture to transfer visible images to infrared domain 2022(Pix2Pix, CycleGAN, thermaGAN)
                 Evaluate the performance of each network over five differ- ent metrics:
                      Structural Similarity Index Measure (SSIM, see Eq. (8) ), Mean Structural Similarity Index Measure (MSSIM),
                      Learned Perceptual Image Patch Similarity (LPIPS), L1 (pixel by pixel, see Eq. (5) ) norm and Peak Signal-to-Noise Ratio (PSNR).
             *Attention GAN : Converting Optical Videos to Infrared Videos Using Attention GAN and Its Impact on Target Detection and Classification Performance 2021.         
             *GAN for visible to infrared video conversion 2020.      
                     VEDAI : Vehicle detection in aerial imagery: a small target detection benchmark, 2015.(vehicle detection in aerial imagery)
                     FLIR : https://www.flir.com/oem/adas/adas- dataset- form/ .
                     KAIST: Multispectral pedestrian detec- tion: benchmark dataset and baselines, 2015.
                     LLVIP: can contribute to the community of computer vision by promoting image fusion, pedestrian detection
                             and image-to-image translation in very low-light applications 
                           （The wavelength: 8~14um (thermal infrared images)):pix2pixGAN, imagefusion_densefuse, FusionGAN
                     The Large-scale Scene Understanding (LSUN): provide a different benchmark for large-scale scene classification and understanding.

             *https://towardsdatascience.com/what-are-stable-diffusion-models-and-why-are-they-a-step-forward-for-image-generation-aa1182801d46.
             *https://lilianweng.github.io/posts/2021-07-11-diffusion-models/
             *https://theaisummer.com/diffusion-models/
             *Inside Meta AI’s Make-A-Video: The New Super Model that can Generate Videos from Textual Input.
             *Generative adversarial networks for visible to infrared video conversion 2020.
            *Synthetic data generation for end-to-end thermal infrared tracking 2018.
            *Transgan: Two transformers can make one strong gan 2021.
            *From IR Images to Point Clouds to Pose: Point Cloud-Based AR Glasses Pose Estimation 2021.

   - Infar Dataset: infrared action recognition at different times, 2020.

   -Transferable Feature Representation for Visible-to-Infrared Cross-Dataset Human Action Recognition 2019:
       Recently, infrared human action recognition has attracted increasing attention for it has many advantages over visible light,
        that is, being robust to illumination change and shadows. However, the infrared action data is limited until now, 
       which degrades the performance of infrared action recognition. Motivated by the idea of transfer learning, an infrared human action recognition framework using auxiliary data from visible light is proposed to solve the problem of limited infrared action data.
       In the proposed framework, we first construct a novel Cross-Dataset Feature Alignment and Generalization (CDFAG) framework to map the infrared data and visible light data into a common feature space, 
       where Kernel Manifold Alignment (KEMA) and a dual alignedto-generalized encoders (AGE) model are employed to represent the feature. 
       Then, a support vector machine (SVM) is trained, using both the infrared data and visible light data, and can classify the features derived from infrared data. 
       The proposed method is evaluated on InfAR, which is a publicly available infrared human action dataset. To build up auxiliary data, we set up a novel visible light action dataset XD145.
       Experimental results show that the proposed method can achieve state-of-the-art performance compared with several transfer learning and domain adaptation methods.

   - data transformation, regularization and augmentation strategies timm
   - Torchvision s' transforms API now support native object detection, segmentation &videos tasks
         pytorch.org/blog/Extending Torchvision's Transforms to object detetcion, segmentation & videos tasks
   - how to perform Data augmentation in NLP projects: https://bit.ly/3FGjQvD
   -https://github.com/pytorch/vision/blob/main/torchvision/datasets/folder.py
     -github.com//jinwchoi/awesome-action-recognition
             Action Recognition and Video Understanding
             Object Recognition
             Pose Estimation
             Competitions
        Useful Code Repos on Video Representation Learning
        Video Representation
        Action Classification
        Skeleton-Based Action Classification
        Temporal Action Detection
        Spatio-Temporal Action Detection
        Ego-Centric Action Recognition
        Miscellaneous
        Action Recognition Datasets
  
        Pose Estimation
         -AlphaPose - PyTorch based realtime and accurate pose estimation and tracking tool from SJTU.
         -Detect-and-Track: Efficient Pose Estimation in Videos - R. Girdhar et al., arXiv2017.
         -OpenPose Library - Caffe based realtime pose estimation library from CMU.
         -Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields - Z. Cao et al, CVPR2017. [code] depends on the [caffe RT pose] - Earlier version of OpenPose from CMU.
         -DensePose [code] - Dense pose human estimation in the wild implemented in the Detectron framework.
         -MultiPoseNet: Fast Multi-Person Pose Estimation using Pose Residual Network - M. Kocabas et al, ECCV2018. [code]
         -DeepLabCut: markerless pose estimation of user-defined body parts with deep learning - A. Mathis et al, Nature Neuroscience 2018. [code]
      Competitions
         -ActEV (Activities in Extended Video - Activity detection in security camera videos. Runs through 2021. Hosted by NIST.
   
    -https://docs.nvidia.com/deeplearning/dali/user-guide/docs/
    -https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/sequence_processing/video/video_reader_label_example.html
    -https://github.com/NVIDIA/DALI
    -https://github.com/gsig/PyVideoResearch/tree/master/datasets

1-Supervised Learning for dense Vision tasks in infrared videos


      
    
     https://github.com/DirtyHarryLYL/Transformer-in-Vision
     Attention mechanisms and deep learning for machine vision: A survey of the state of the art 2021.
     BERT Baseline - Kaggle
   

      AMMUS: A survey of Transformer based Pretrained Models in NLP 2021

      

1-1-object Detection for outdoor surveillance and intrusion detetcion
         *End-to-end  object detection with transformers 2020.
         *Training data-efficient image transformers & distillation through attention 2021.
1-2-object Segmentation for outdoor surveillance and intrusion detetcion:
        *
        *Training data-efficient image transformers & distillation through attention 2021.
1-3 object Classification for outdoor surveillance and intrusion detetcion:

                   *An image is worth 16x16 words: transformers for image recognition at scale 2021.
                   *Training data-efficient image transformers & distillation through attention 2021.

1-4 object Localization  for outdoor surveillance and intrusion detetcion:
                   *Training data-efficient image transformers & distillation through attention 2021.
1-5-Tracking:
        *Deep learning for visual tracking: A comprehensive survey 2021.
        *Efficient Visual  Tracking  with exemplar transformers 2022.
        *SwinTrack: A Simple and Strong Baseline for Transformer Tracking 2021.
        *Tracking: LiDAR-based 3D Object Tracking with Transformer framework .
                     *Reference: 3D Object Tracking with Transformer 2021.(LTTR)
                                           Transformers in 3D Point Clouds: A Survey, 2022.
                        
        *End-to-end human pose and mesh reconstruction with transformers 2021.
        *VoRTX: Volumetric 3D Reconstruction With Transformers for Voxelwise View Selection and Fusion 2021
            
1-6-Outlier/anomaly detetcion:

1-7 - Unified /generalizable Framework for Real-world Skeleton Action Recognition
         Action recognition based on skeleton data has recently witnessed increasing attention and progress.
         State-of-theart approaches can effectively extract features on human skeletons relying on the pre-defined human topology.
      
       Reference:
              *https://github.com/negarhdr/skeleton-based-action-recognition/
              *https://github.com/YangDi666/UNIK
              * VISION TRANSFORMERS FOR ACTION RECOGNITION: A SURVEY 2022.
              *Spatial temporal transformer network for skeleton-based action recognition 2021.
              *Skeleton based acttion recognition via spatial and temporal transformer.

1-8- Multi-modal Action Recognition:

                          - RGB videos.
                         - depth map sequences.
                         - 3D skeletal data (3D coordinates of 25 major body joints)
                         - infrared (IR) videos.
        *Knowledge fusion transformers for video action recognition.
        *Knowledge Distillation for Action Recognition Based on RGB and Infrared Videos 2022.
        * VISION TRANSFORMERS FOR ACTION RECOGNITION: A SURVEY 2022.
         *Video Transformers: A Survey, 2022
         *Video Action Transformer Network 2019.
         *Vivit: A video vision transformer 2021.

        *Actor-transformers for group activity recognition. 2020.
         *https://github.com/xueyee/GroupFormer
       
     
         

        *Ttpp: Temporal transformer with progressive prediction for efficient action anticipation 2021.
        *Bridging the gap between Human Action Recognition and Online Action Detection 2021.
        *LocFormer: Enabling Transformers to Perform Temporal Moment Localization on Long Untrimmed Videos With a Feature Sampling Approach 2021


1-9-Egocentric Vision-based situation Recognition:

          -Egocentric Vision-based Action Recognition: A survey   2022.
         - Trear: Transformer-based rgb-d egocentric action recognition 2021.
          https://github.com/EgocentricVision
          https://github.com/EgocentricVision#datasets, EPIC kitchen, etc: see for pfe, #repositories.
         
         multi-view camera (vision)

1-10-Visual language Learning for grounded situation description (Vision and Language)/Dense video captioning
                                    Dense video captioning is a newly emerging task that aims at both localizing and describing all events in a video
 
  https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification
  https://github.com/huggingface/transformers/tree/main/examples/pytorch
  https://github.com/huggingface/transformers/tree/main/examples/research_projects

   *HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips 2019.
   *End-to-End Learning of Visual Representations from Uncurated Instructional Videos 2019
   *End to end dense video captionning with masked transformers 2018.
   *ALIGN : Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision 2021.
   *CLIP(Contrastive Language-Image Pre-Training): Learning Transferable Visual Models From Natural Language Supervision 2021.
   *Labelling unlabelled videos from scratch with multi-modal self-supervision 2020.
   *Multi-modal self supervised learning from videos 2021(EPFL)
   *Broaden your views for self supervised video learning 2021(EPFL)
   *Fine-grained Multi-Modal Self-Supervised Learning 2021.
   *VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text 2021.
   *Self-Supervised MultiModal Versatile Networks 2021 :
             https://github.com/deepmind/deepmind-research/tree/master/mmv

   *Explore and Match: End-to-End Video Grounding with Transformer 2022.
   *TransVG: End-to-End Visual Grounding with Transformers 2021
   *Visual Grounding with Transformers 2021
   **Grounded Situation Recognition with Transformers 2021.
   *End-to-End Dense Video Grounding via Parallel Regression 2021.
   *On Pursuit of Designing Multi-modal Transformer for Video Grounding 2021.
   *Multi-View Transformer for 3D Visual Grounding 2022.
   *Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue System 2019
         (audio+visual)
   
     UniT: Multimodal Multitask Learning with a Unified Transformer
     Multimodal Incremental Transformer with Visual Grounding for Visual Dialogue Generation 2021.
     Reference:
              *https://mmf.sh/docs
              * https://github.com/facebookresearch/mmf
              * Vision-language Pre-training: Basics, recent Advances, and Future Trends 2021.

See also: Perceiver IO, Data2vec 
       notes on H:\Deep learning_Infrared images or video\Transformers\Papers_to work on Novembre_2021\global attention _self ou unsupervised training\related to Data2vec
               H:\Deep learning_Infrared images or video\Transformers\Papers_to work on Novembre_2021\multi-modal embedding space_fusion approach for self supervised
               H:\Deep learning_Infrared images or video\Transformers\Papers_to work on Novembre_2021\Grounded situation based transformer
                  H:\Deep learning_Infrared images or video\Transformers\Papers_to work on Novembre_2021

1-11- Named entity recognition for grounded situation recognition:  
      https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification

     Reference:
       * Vision-language Pre-training: Basics, recent Advances, and Future Trends 2021.
      * https://github.com/allenai/swig,
      * https://github.com/TheShadow29/vognet-pytorch:
         Evaluation metrics : 
                    Accuracy, Strict accuracy, consistency, video accuracy.

           - Video action transformer network 2019 paper with code 2019  (Faster RCNN)
           - VidTr: Video Transformer Without Convolutions 2021.
           - Grounded Video Description 2019: (ii) ImgGrnd, (ii) VidGrnd

           - Video Object Grounding using Semantic Roles in Language Description 2020 (vognet)
       *https://github.com/jhcho99/gsrtr, https://github.com/jhcho99/
       https://github.com/jhcho99/CoFormer.
       https://github.com/kellyiss/SituFormer

       * Vision-and-Language Pretrained Models: A Survey, 2022.

      - Named-entity recognition platforms
          Notable NER platforms include:

               *GATE supports NER across many languages and domains out of the box, usable via a graphical interface and a Java API.
               *OpenNLP includes rule-based and statistical named-entity recognition.
               *SpaCy features fast statistical NER as well as an open-source named-entity visualizer.

     - Named entity recognition models in huggingface.
     - SayCan: Do  As I can, Not as Isay: Grounding Language in Robotivs Affordances 2022(see blog, google-AI-youtube, Demo, github)

Pretrained models similar to our specific task,  fine tuning with different fine-tuning schemes: see DINO may be.
This process will also achieve better results than training from scratch (unless you have lots of data),
which is why you should always try to leverage a pretrained model — one as close as possible to the task you have at hand — and fine-tune it.


pfe: https:// meduim.com/standford-cs224w/graphs-are-all-you-need-generating-multi-modal-representations-for-vqa-744a8a1ad448:
multi-modal graph Networks for compositonal generalization in visual questionning answering (Princeton university, NIPS 2020)

idea: predicts the trajectory of the eye from the input image.(AI-Scolar)




1-12- facial expression recognition  # see Thales also: thermal face and landmark detection for unconstrained cross-spectral face recognition UCB2022.
      Charlotte-ThermalFace: A Fully Annotated Thermal Infrared Face Dataset with Various Environmental Conditions and Distances 2022.
      - Using Facial Landmark Detection on Thermal Images as a Novel Prognostic Tool for Emergency Departments 2022.
      - Face Recognition in Unconstrained Conditions: A Systematic Review 2019
      - Multispectral Facial Recognition in the Wild 2022
      - Heterogeneous Visible-Thermal and Visible-Infrared Face Recognition Using Cross-Modality Discriminator Network and Unit-Class Loss



      unconstrained face recognition:Labeled Faces in the Wild datset(LFW Face Database)
1-13-Hand Gesture Languages:
                   https://aiia.csd.auth.gr/auth-uav-gesture-dataset/  ( infrared, skeleton)
                   Multi-Modal Dataset for Hand Gesture Recognition:
                        https://www.kaggle.com/datasets/gti-upm/multimodhandgestrec
                  A tranformer based network for Dynamic Hand gesture recognition      (RGB-D devices)

1-14 Sign/Mime language Recognition.
       Sign language Recognition with transformer Networks.
   
1-15-Hyper_parameter optimization with Nature Inspired metaheuristic optimization algorithms

2-Self supervised Learning on images , videos, depth maps, skeletons for  outdoor surveillance and intrusion detetcion.
see also: H:\Deep learning_Infrared images or video\Transformers\Papers_to work on Novembre_2021\global attention _self ou unsupervised training
     Recently, computer vision systems have made considerable progress. Most of them are still based on supervised learning. 
     However, the success of such a learning paradigm relies on a large amount of labeled data, which is not always available, 
     is often prohibitively expensive to acquire, and is hampered by the cost of the required human annotation.
     Furthermore, these supervised systems are tailored to specific scenarios, for example a model trained on the ImageNet dataset (ILSVRC-2012) 
     can only recognize 1000 semantic categories or a model trained to perceive road traffic in daylight may not work in the dark. 
     It is simply not possible to collect labeled data for all the things we would like machines to do and we cannot label more and more data. 


     Therefore, a major research effort is currently devoted to systems that can adapt to new conditions without the need for expensive supervision. 
     This effort includes recent advances in transfer learning, domain adaptation, semi-supervised, weakly supervised, unsupervised 
     and self-supervised learning.

       Self-supervised transformers can produce finer features than those obtained by supervised approaches without any labeling load.  

            *M3Video: Masked Motion Modeling for Self-Supervised Video Representation Learning 2022.
            *Video Transformers: A Survey, 2022
            *https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html:
            *Transformers in Action: Weakly Supervised Action Segmentation 2022.
            *Google’s SimCLR library: https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html
            *Self supervised Library: jrodthoughts.meduim.com/Lightly is one of the first open source frameworks for self supervised learning
                 - https://github.com/lightly-ai/lightly
          
                  Barlow Twins
                  BYOL
                  DCL & DCLW
                  DINO
                  MAE
                  MSN
                  MoCo
                  NNCLR
                  SimCLR
                  SimSiam
                  SMoG
                  SwaV
     for Sketon data: Self-supervised 3D Skeleton Action Representation Learning with Motion Consistency and Continuity 2021.
                      Self-supervised 3D hand pose estimation through training by fitting 221. (hand tracking)

     (for videos and actions )Guess what Moves: Unsupervised Video and Image Segmentation by Anticipating Motion 2022.

3-General purpose backbone learning for dense vision tasks:
    
      * Large-batch Optimization for Dense Visual Predictions 2022_https://github.com/Sense-X/AGVM
      *Vision transformers for dense prediction, 2021


   
4-General purpose model (All for One:  Multi-Task)

                   https://cs224d.stanford.edu/reports/McCannRoth.pdf

                   Gato:https://github.com/OrigamiDream/Gato


5- Contextual challenging Transformer based network for efficient intrusion detetcion in infarred. 
    multi-scale, distractor, etc.
      Attention-Based Multi-Task Learning For Fine-Grained Image Classification 2021.
6-Fusion : 
7-Interpretable model:
     complex event processing, Dynamic IR challenges
       VEKG: Video Event Knowledge Graph to Represent Video Streams for Complex Event Pattern Matching 2019.
Author: Anurag Arnab
       Unified Graph Structured Models for Video Understanding 2021
       Dynamic Graph Message Passing Networks 2019

8-Neuroscience module:
     bog of facebook/Martin Ciupa: consciousnesss is an important topic.  
             Transdisciplinity and consciousness; toward an integrated  model 
             quantim mechanisms
9-Federated  Learning:
                        -FLED-Block: Federated Learning Ensembled Deep Learning Blockchain Model for COVID-19 Prediction, 2022.
                        -International Joint Conference on Neural Networks 2022 (IJCNN) on  Federated Learning  and Cooperative Neural Network (CoNN): 18-23 July 2022.
                        -Applications and Challenges of Federated Learning Paradigm in the Big Data Era with Special Emphasis on COVID-19 2022.
                        -federated self supervised learning for acoustic event classification 2022.
10-Meta Learning:
               Environment Adaptive RFID-Based 3D Human Pose Tracking With a Meta-Learning Approach 2022.

11-Deploy the application into production.

Surveillance system

MTEB: Massive Text Embedding Benchmark: https://huggingface.co/blog/mteb
     MTEB is a massive benchmark for measuring the performance of text embedding models on diverse embedding tasks.
     https://huggingface.co/spaces/mteb/leaderboard


12- Mixed reality/3D representation
       https://github.com/google-research-datasets/Objectron
 

13-SLAM and Deep Learning for 3D Indoor Scene Understanding 2018.(John B. McCormac)
     Multi-Frame Self-Supervised Depth with Transformers 2022.

14- Visualization/Computer graphics

       Tableau



Try to use your custdom dataset: see blogs can help you/ colab 
Extend Classifying each word in a sentence tasks to videos

pfe: https://huggingface.co/blog/train-decision-transformers




Next step :  try to put ViT, Detr into  commun plateform,  pipeline


%https://github.com/fc7/LaTeX-Decode
#https://metacpan.org/dist/LaTeX-Decode/view/bin/latex2utf8










